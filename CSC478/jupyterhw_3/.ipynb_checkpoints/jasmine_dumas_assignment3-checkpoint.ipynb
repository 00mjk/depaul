{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jasmine Dumas (1523905)\n",
    "### CSC 478: Programming Machine Learning Applications - Autumn 2016\n",
    "### [Assignment #3](http://facweb.cs.depaul.edu/mobasher/classes/csc478/Assignments/assign3.html)\n",
    "### Due: Thursday, November 3, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment you will experiment with various regression approaches and you'll get your feet wet with some clustering. We will rely on subsets of some real-world data sets and on tools from the Scikit-learn machine learning package for Python as well as modules from the textbook code (Machine Learning in Action, Chapters 8 and 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, SGDRegressor\n",
    "import pylab as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Linear Regression [Dataset: communities.zip]**\n",
    "\n",
    "  * For this problem you will experiment with linear regression models to make predictions with numerical data. You will also explore more systematic methods for feature selection and for optimizing model parameters (model selection). The data set you will use is a subset of the \"Communities and Crime\" data set that combines information from the 1990 census data as well as FBI crime data from 1995. Please read the full description of the data, including the description and statistics on different variables. The target attribute for regression purposes is \"ViolentCrimesPerPop\". The two identifier attributes \"state\" and \"community name\" should be excluded for the regression task.\n",
    "\n",
    "  * Your tasks in this problem are the following [Note: for these tasks you will use the available linear-models from scikit-learn as well as the implementations of the relevant approaches from the Ch. 8 of MLA] .**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. **Load and preprocess the data using Pandas or Numpy and, if necessary, preprocessing functions from scikit-learn.** \n",
    "  * The provided data is already normalized (see description), so there is no need for additional normalization. \n",
    "  * Compute and display basic statistics (mean, standard deviation, min, max, etc.) for each of the variables in the data set. Separate the target attribute for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state        communityname  population  householdsize  racepctblack  \\\n",
       "0      8         Lakewoodcity        0.19           0.33          0.02   \n",
       "1     53          Tukwilacity        0.00           0.16          0.12   \n",
       "2     24         Aberdeentown        0.00           0.42          0.49   \n",
       "3     34  Willingborotownship        0.04           0.77          1.00   \n",
       "4     42    Bethlehemtownship        0.01           0.55          0.02   \n",
       "\n",
       "   racePctWhite  racePctAsian  racePctHisp  agePct12t21  agePct12t29  \\\n",
       "0          0.90          0.12         0.17         0.34         0.47   \n",
       "1          0.74          0.45         0.07         0.26         0.59   \n",
       "2          0.56          0.17         0.04         0.39         0.47   \n",
       "3          0.08          0.12         0.10         0.51         0.50   \n",
       "4          0.95          0.09         0.05         0.38         0.38   \n",
       "\n",
       "          ...           NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "0         ...                 0.0            0.12              0.42   \n",
       "1         ...                 0.0            0.21              0.50   \n",
       "2         ...                 0.0            0.14              0.49   \n",
       "3         ...                 0.0            0.19              0.30   \n",
       "4         ...                 0.0            0.11              0.72   \n",
       "\n",
       "   PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "0            0.50           0.51            0.64      0.12     0.26   \n",
       "1            0.34           0.60            0.52      0.02     0.12   \n",
       "2            0.54           0.67            0.56      0.01     0.21   \n",
       "3            0.73           0.64            0.65      0.02     0.39   \n",
       "4            0.64           0.61            0.53      0.04     0.09   \n",
       "\n",
       "   PctUsePubTrans  ViolentCrimesPerPop  \n",
       "0            0.20                 0.20  \n",
       "1            0.45                 0.67  \n",
       "2            0.02                 0.43  \n",
       "3            0.28                 0.12  \n",
       "4            0.02                 0.03  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comms = pd.read_csv(\"communities/communities.csv\")\n",
    "comms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1994, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many columns and rows?\n",
    "comms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Jacksonvillecity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.683551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057593</td>\n",
       "      <td>0.463395</td>\n",
       "      <td>0.179629</td>\n",
       "      <td>0.753716</td>\n",
       "      <td>0.153681</td>\n",
       "      <td>0.144022</td>\n",
       "      <td>0.424218</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.215552</td>\n",
       "      <td>0.608892</td>\n",
       "      <td>0.535050</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.651530</td>\n",
       "      <td>0.065231</td>\n",
       "      <td>0.232854</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>0.237979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.397553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>0.163717</td>\n",
       "      <td>0.253442</td>\n",
       "      <td>0.244039</td>\n",
       "      <td>0.208877</td>\n",
       "      <td>0.232492</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.231134</td>\n",
       "      <td>0.204329</td>\n",
       "      <td>0.181352</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.198221</td>\n",
       "      <td>0.109459</td>\n",
       "      <td>0.203092</td>\n",
       "      <td>0.229055</td>\n",
       "      <td>0.232985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              state     communityname   population  householdsize  \\\n",
       "count   1994.000000              1994  1994.000000    1994.000000   \n",
       "unique          NaN              1828          NaN            NaN   \n",
       "top             NaN  Jacksonvillecity          NaN            NaN   \n",
       "freq            NaN                 5          NaN            NaN   \n",
       "mean      28.683551               NaN     0.057593       0.463395   \n",
       "std       16.397553               NaN     0.126906       0.163717   \n",
       "min        1.000000               NaN     0.000000       0.000000   \n",
       "25%       12.000000               NaN     0.010000       0.350000   \n",
       "50%       34.000000               NaN     0.020000       0.440000   \n",
       "75%       42.000000               NaN     0.050000       0.540000   \n",
       "max       56.000000               NaN     1.000000       1.000000   \n",
       "\n",
       "        racepctblack  racePctWhite  racePctAsian  racePctHisp  agePct12t21  \\\n",
       "count    1994.000000   1994.000000   1994.000000  1994.000000  1994.000000   \n",
       "unique           NaN           NaN           NaN          NaN          NaN   \n",
       "top              NaN           NaN           NaN          NaN          NaN   \n",
       "freq             NaN           NaN           NaN          NaN          NaN   \n",
       "mean        0.179629      0.753716      0.153681     0.144022     0.424218   \n",
       "std         0.253442      0.244039      0.208877     0.232492     0.155196   \n",
       "min         0.000000      0.000000      0.000000     0.000000     0.000000   \n",
       "25%         0.020000      0.630000      0.040000     0.010000     0.340000   \n",
       "50%         0.060000      0.850000      0.070000     0.040000     0.400000   \n",
       "75%         0.230000      0.940000      0.170000     0.160000     0.470000   \n",
       "max         1.000000      1.000000      1.000000     1.000000     1.000000   \n",
       "\n",
       "        agePct12t29         ...             NumStreet  PctForeignBorn  \\\n",
       "count   1994.000000         ...           1994.000000     1994.000000   \n",
       "unique          NaN         ...                   NaN             NaN   \n",
       "top             NaN         ...                   NaN             NaN   \n",
       "freq            NaN         ...                   NaN             NaN   \n",
       "mean       0.493867         ...              0.022778        0.215552   \n",
       "std        0.143564         ...              0.100400        0.231134   \n",
       "min        0.000000         ...              0.000000        0.000000   \n",
       "25%        0.410000         ...              0.000000        0.060000   \n",
       "50%        0.480000         ...              0.000000        0.130000   \n",
       "75%        0.540000         ...              0.000000        0.280000   \n",
       "max        1.000000         ...              1.000000        1.000000   \n",
       "\n",
       "        PctBornSameState  PctSameHouse85  PctSameCity85  PctSameState85  \\\n",
       "count        1994.000000     1994.000000    1994.000000     1994.000000   \n",
       "unique               NaN             NaN            NaN             NaN   \n",
       "top                  NaN             NaN            NaN             NaN   \n",
       "freq                 NaN             NaN            NaN             NaN   \n",
       "mean            0.608892        0.535050       0.626424        0.651530   \n",
       "std             0.204329        0.181352       0.200521        0.198221   \n",
       "min             0.000000        0.000000       0.000000        0.000000   \n",
       "25%             0.470000        0.420000       0.520000        0.560000   \n",
       "50%             0.630000        0.540000       0.670000        0.700000   \n",
       "75%             0.777500        0.660000       0.770000        0.790000   \n",
       "max             1.000000        1.000000       1.000000        1.000000   \n",
       "\n",
       "           LandArea      PopDens  PctUsePubTrans  ViolentCrimesPerPop  \n",
       "count   1994.000000  1994.000000     1994.000000          1994.000000  \n",
       "unique          NaN          NaN             NaN                  NaN  \n",
       "top             NaN          NaN             NaN                  NaN  \n",
       "freq            NaN          NaN             NaN                  NaN  \n",
       "mean       0.065231     0.232854        0.161685             0.237979  \n",
       "std        0.109459     0.203092        0.229055             0.232985  \n",
       "min        0.000000     0.000000        0.000000             0.000000  \n",
       "25%        0.020000     0.100000        0.020000             0.070000  \n",
       "50%        0.040000     0.170000        0.070000             0.150000  \n",
       "75%        0.070000     0.280000        0.190000             0.330000  \n",
       "max        1.000000     1.000000        1.000000             1.000000  \n",
       "\n",
       "[11 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the basic statistics for each of the variable?\n",
    "comms.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle missing data\n",
    "np.sum(np.array(pd.isnull(comms)),0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.36', '0.22', '0.28', '0.51', '0.48', '0.24', '0.18', '0.29',\n",
       "       '0.17', '0.34', '0.35', '0.13', '0.33', '0.2', '1', '0.72', '0',\n",
       "       '0.19', '0.3', '0.38', '0.14', '0.26', '0.64', '0.25', '0.37',\n",
       "       '0.16', '0.15', '0.76', '0.4', '0.42', '0.23', '0.31', '0.32',\n",
       "       '0.5', '0.66', '0.21', '0.7', '0.27', '0.11', '0.55', '0.95',\n",
       "       '0.03', '0.45', '0.08', '0.43', '0.62', '0.02', '0.41', '?', '0.39',\n",
       "       '0.88', '0.71', '0.44', '0.47', '0.09', '0.53', '0.1', '0.46',\n",
       "       '0.05', '0.52', '0.75', '0.06', '0.93', '0.12', '0.77', '0.69',\n",
       "       '0.86', '0.73', '0.67', '0.84', '0.81', '0.54', '0.59', '0.01',\n",
       "       '0.68', '0.98', '0.04', '0.61', '0.9', '0.57', '0.49', '0.56',\n",
       "       '0.07', '0.92', '0.6', '0.94', '0.63', '0.87', '0.79', '0.99',\n",
       "       '0.58', '0.83', '0.85', '0.8', '0.82', '0.74', '0.65', '0.89'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comms[\"OtherPerCap\"].unique() # there is that ? used for a missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                      int64\n",
       "communityname             object\n",
       "population               float64\n",
       "householdsize            float64\n",
       "racepctblack             float64\n",
       "racePctWhite             float64\n",
       "racePctAsian             float64\n",
       "racePctHisp              float64\n",
       "agePct12t21              float64\n",
       "agePct12t29              float64\n",
       "agePct16t24              float64\n",
       "agePct65up               float64\n",
       "numbUrban                float64\n",
       "pctUrban                 float64\n",
       "medIncome                float64\n",
       "pctWWage                 float64\n",
       "pctWFarmSelf             float64\n",
       "pctWInvInc               float64\n",
       "pctWSocSec               float64\n",
       "pctWPubAsst              float64\n",
       "pctWRetire               float64\n",
       "medFamInc                float64\n",
       "perCapInc                float64\n",
       "whitePerCap              float64\n",
       "blackPerCap              float64\n",
       "indianPerCap             float64\n",
       "AsianPerCap              float64\n",
       "OtherPerCap               object\n",
       "HispPerCap               float64\n",
       "NumUnderPov              float64\n",
       "                          ...   \n",
       "MedNumBR                 float64\n",
       "HousVacant               float64\n",
       "PctHousOccup             float64\n",
       "PctHousOwnOcc            float64\n",
       "PctVacantBoarded         float64\n",
       "PctVacMore6Mos           float64\n",
       "MedYrHousBuilt           float64\n",
       "PctHousNoPhone           float64\n",
       "PctWOFullPlumb           float64\n",
       "OwnOccLowQuart           float64\n",
       "OwnOccMedVal             float64\n",
       "OwnOccHiQuart            float64\n",
       "RentLowQ                 float64\n",
       "RentMedian               float64\n",
       "RentHighQ                float64\n",
       "MedRent                  float64\n",
       "MedRentPctHousInc        float64\n",
       "MedOwnCostPctInc         float64\n",
       "MedOwnCostPctIncNoMtg    float64\n",
       "NumInShelters            float64\n",
       "NumStreet                float64\n",
       "PctForeignBorn           float64\n",
       "PctBornSameState         float64\n",
       "PctSameHouse85           float64\n",
       "PctSameCity85            float64\n",
       "PctSameState85           float64\n",
       "LandArea                 float64\n",
       "PopDens                  float64\n",
       "PctUsePubTrans           float64\n",
       "ViolentCrimesPerPop      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comms.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                      int64\n",
       "communityname             object\n",
       "population               float64\n",
       "householdsize            float64\n",
       "racepctblack             float64\n",
       "racePctWhite             float64\n",
       "racePctAsian             float64\n",
       "racePctHisp              float64\n",
       "agePct12t21              float64\n",
       "agePct12t29              float64\n",
       "agePct16t24              float64\n",
       "agePct65up               float64\n",
       "numbUrban                float64\n",
       "pctUrban                 float64\n",
       "medIncome                float64\n",
       "pctWWage                 float64\n",
       "pctWFarmSelf             float64\n",
       "pctWInvInc               float64\n",
       "pctWSocSec               float64\n",
       "pctWPubAsst              float64\n",
       "pctWRetire               float64\n",
       "medFamInc                float64\n",
       "perCapInc                float64\n",
       "whitePerCap              float64\n",
       "blackPerCap              float64\n",
       "indianPerCap             float64\n",
       "AsianPerCap              float64\n",
       "OtherPerCap              float64\n",
       "HispPerCap               float64\n",
       "NumUnderPov              float64\n",
       "                          ...   \n",
       "MedNumBR                 float64\n",
       "HousVacant               float64\n",
       "PctHousOccup             float64\n",
       "PctHousOwnOcc            float64\n",
       "PctVacantBoarded         float64\n",
       "PctVacMore6Mos           float64\n",
       "MedYrHousBuilt           float64\n",
       "PctHousNoPhone           float64\n",
       "PctWOFullPlumb           float64\n",
       "OwnOccLowQuart           float64\n",
       "OwnOccMedVal             float64\n",
       "OwnOccHiQuart            float64\n",
       "RentLowQ                 float64\n",
       "RentMedian               float64\n",
       "RentHighQ                float64\n",
       "MedRent                  float64\n",
       "MedRentPctHousInc        float64\n",
       "MedOwnCostPctInc         float64\n",
       "MedOwnCostPctIncNoMtg    float64\n",
       "NumInShelters            float64\n",
       "NumStreet                float64\n",
       "PctForeignBorn           float64\n",
       "PctBornSameState         float64\n",
       "PctSameHouse85           float64\n",
       "PctSameCity85            float64\n",
       "PctSameState85           float64\n",
       "LandArea                 float64\n",
       "PopDens                  float64\n",
       "PctUsePubTrans           float64\n",
       "ViolentCrimesPerPop      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comms.OtherPerCap = pd.to_numeric(comms.OtherPerCap, errors='coerce') # coerce arg turns failures into NaN\n",
    "comms.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comms = comms.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# seperate the target attribute\n",
    "y = np.array(comms.ViolentCrimesPerPop)\n",
    "X = np.array(comms.drop(['ViolentCrimesPerPop', 'state', 'communityname'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1993, 97)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that was successful\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2 ,  0.67,  0.43, ...,  0.23,  0.19,  0.48])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1993,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. **Perform standard linear regression on data using the implementation for Ch. 8 of MLA.** \n",
    "  * Compute the RMSE value on the full training data. \n",
    "  * Also, plot the correlation between the predicted and actual values of the target attribute. Display the obtained regression coefficients (weights). \n",
    "  * Finally, perform 10-fold cross-validation and compare the cross-validation RMSE to the training RMSE (for cross validation, you may use the KFold module from sklearn.cross_validation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Machine Learning in Action - Ch. 8, page 157\n",
    "\n",
    "#we need to add a row of 1's to the X matrix since we want a constant in the model\n",
    "x_var = np.array(X)\n",
    "x_var = np.array([np.concatenate((v,[1])) for v in x_var])\n",
    "\n",
    "def standRegres(xArr, yArr):\n",
    "    xMat = np.matrix(xArr) ; yMat = np.matrix(yArr).T\n",
    "    xTx = xMat.T*xMat\n",
    "    if np.linalg.det(xTx) == 0.0:\n",
    "        print(\"This matrix is singular, cannot do inverse\")\n",
    "    else:\n",
    "        ws = xTx.I * (xMat.T*yMat)\n",
    "        return ws\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_linear = standRegres(x_var, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  1.58394687e-01],\n",
       "        [ -3.02481869e-02],\n",
       "        [  2.12229063e-01],\n",
       "        [ -3.97237986e-02],\n",
       "        [ -1.27930326e-02],\n",
       "        [  6.36900639e-02],\n",
       "        [  1.22194419e-01],\n",
       "        [ -2.23124229e-01],\n",
       "        [ -1.42627637e-01],\n",
       "        [  5.64658800e-02],\n",
       "        [ -2.60230134e-01],\n",
       "        [  4.65037847e-02],\n",
       "        [ -2.00798143e-01],\n",
       "        [ -2.08126761e-01],\n",
       "        [  4.70792802e-02],\n",
       "        [ -1.73534979e-01],\n",
       "        [  5.82291674e-02],\n",
       "        [  1.05064444e-02],\n",
       "        [ -9.22106451e-02],\n",
       "        [  2.72565616e-01],\n",
       "        [  9.72713359e-02],\n",
       "        [ -3.26302914e-01],\n",
       "        [ -2.89431388e-02],\n",
       "        [ -3.59461641e-02],\n",
       "        [  2.28885702e-02],\n",
       "        [  4.31169895e-02],\n",
       "        [  3.76737976e-02],\n",
       "        [  1.19950473e-01],\n",
       "        [ -1.83693623e-01],\n",
       "        [ -9.47657739e-02],\n",
       "        [  5.55240764e-02],\n",
       "        [  1.07281673e-01],\n",
       "        [  3.24692051e-03],\n",
       "        [  2.34646790e-01],\n",
       "        [ -3.87649999e-02],\n",
       "        [ -1.03179240e-02],\n",
       "        [  4.87331629e-01],\n",
       "        [  2.23501778e-01],\n",
       "        [  1.95680279e-01],\n",
       "        [ -6.09603366e-01],\n",
       "        [ -1.37531328e-01],\n",
       "        [  5.78881584e-02],\n",
       "        [ -3.48705517e-01],\n",
       "        [ -3.63011027e-02],\n",
       "        [  3.18567061e-04],\n",
       "        [  5.73144283e-02],\n",
       "        [ -1.83223819e-01],\n",
       "        [ -1.56736510e-01],\n",
       "        [  1.30876568e-01],\n",
       "        [ -1.42989741e-01],\n",
       "        [  2.41003168e-02],\n",
       "        [  3.51231959e-02],\n",
       "        [ -7.51880947e-02],\n",
       "        [  3.13067150e-02],\n",
       "        [ -3.09769559e-02],\n",
       "        [ -2.23123389e-01],\n",
       "        [  4.44778318e-01],\n",
       "        [ -1.90505607e-01],\n",
       "        [ -2.11867268e-02],\n",
       "        [ -1.39832020e-01],\n",
       "        [  5.72276516e-02],\n",
       "        [ -2.07798143e-01],\n",
       "        [  6.47474344e-01],\n",
       "        [ -7.48614235e-02],\n",
       "        [ -2.50464211e-01],\n",
       "        [ -6.69267650e-01],\n",
       "        [  1.97555120e-01],\n",
       "        [  1.03772298e-01],\n",
       "        [  2.93735670e-02],\n",
       "        [  1.66760060e-01],\n",
       "        [ -4.08619231e-02],\n",
       "        [  5.60042500e-01],\n",
       "        [  4.53308898e-02],\n",
       "        [ -7.74693964e-02],\n",
       "        [ -2.95662893e-02],\n",
       "        [  8.75265792e-03],\n",
       "        [ -1.36583666e-02],\n",
       "        [ -3.44122989e-01],\n",
       "        [  2.70216168e-01],\n",
       "        [  8.56985376e-03],\n",
       "        [ -2.34032103e-01],\n",
       "        [ -3.72752186e-02],\n",
       "        [ -6.34433398e-02],\n",
       "        [  3.76117090e-01],\n",
       "        [  3.92332673e-02],\n",
       "        [ -4.37652624e-02],\n",
       "        [ -8.08701392e-02],\n",
       "        [  1.31163307e-01],\n",
       "        [  1.83394279e-01],\n",
       "        [  1.22680856e-01],\n",
       "        [  6.42109584e-03],\n",
       "        [ -2.03383095e-02],\n",
       "        [  2.94915376e-02],\n",
       "        [  1.14868587e-02],\n",
       "        [  2.59657369e-02],\n",
       "        [ -1.25052609e-02],\n",
       "        [ -3.78848193e-02],\n",
       "        [  5.74152313e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12869119]]\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "yHat = x_var*std_linear\n",
    "yHatT = yHat.T\n",
    "err = abs(yHatT - y)\n",
    "total_error = np.dot(err,err.T)\n",
    "# Compute RMSE\n",
    "rmse_train = np.sqrt(total_error/len(yHat))\n",
    "print(rmse_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAF5CAYAAAC83HEwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10616c7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot correlation between the predicted and actual values of the target attribute\n",
    "# Get predicted values\n",
    "xMat = np.matrix(x_var)\n",
    "yMat = np.matrix(y)\n",
    "yHat = xMat*std_linear\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "#ax.scatter(xMat[:,1].flatten(), yMat.T[:,0].flatten())\n",
    "ax.scatter(xMat[:,1].flatten().A[0], yMat.T[:,0].flatten().A[0])\n",
    "\n",
    "xCopy = xMat.copy()\n",
    "xCopy.sort(0)\n",
    "yHat = xCopy*std_linear\n",
    "\n",
    "ax.plot(xCopy[:,1], yHat)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 10-fold cross-validation\n",
    "X_array = np.array(x_var)\n",
    "y_array = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from scipy.stats import sem\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "# Create linear regression object\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "linreg.fit(x_var,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's compute RMSE using 10-fold cross-validation\n",
    "kf = KFold(len(x_var), n_folds=10)\n",
    "xval_err = 0\n",
    "for train,test in kf:\n",
    "    linreg.fit(x_var[train],y[train])\n",
    "    # p = np.array([linreg.predict(xi) for xi in x[test]])\n",
    "    p = linreg.predict(x_var[test])\n",
    "    e = p-y[test]\n",
    "    xval_err += np.dot(e,e)\n",
    "    \n",
    "rmse_10cv = np.sqrt(xval_err/len(x_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Simple Linear Regression\n",
      "RMSE on training: 0.1287\n",
      "RMSE on 10-fold CV: 0.1363\n"
     ]
    }
   ],
   "source": [
    "method_name = 'Simple Linear Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10-fold cross validation RMSE was higher than the original, leading to a more precise model to try an overcome the differences in variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. **Feature Selection:  use the scikit-learn regression model from sklearn.linear_model with a subset of features to perform linear regression. **\n",
    "  * For feature selection, write a script or function that takes as input the training data, target attribute; the model; and any other parameters you find necessary, and returns the optimal percentage of the most informative features to use. Your approach should use k-fold cross-validation on the training data (you can use k=5). You can use feature_selection.SelectPercentile to find the most informative variables. Show the list of most informative variables and their weights [Note: since this is regression not classification, you should use feature_selection.f_regression as scoring function rather than chi2). \n",
    "  * Next, plot the model's mean absolute error values  on cross-validation relative to the percentage of selected features (See scikit-learn's metrics.mean_absolute_error). In order to use cross_validation.cross_val_score with regression you'll need to pass to it scoring='mean_absolute_error' as a parameter. [Hint: for an example of a similar feature selection process please review the class example notebook. Also, review scikit-learn documentation for feature selection.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "\n",
    "for train, test in KFold(n = len(X_array), n_folds=5, random_state = 99):\n",
    "    X_train, y_train = X_array[train], y_array[train]\n",
    "    X_test, y_test = X_array[test], y_array[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "# extract the features with the most predictive power (explains the most variance)\n",
    "selector = SelectPercentile(f_regression, percentile=10)\n",
    "selector.fit(X, y)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "scores /= scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  nan,   0.,\n",
       "         0.,   0.,   0.,   0.,  nan,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. **Next, perform Ridge Regression and Lasso Regression, however this time use the modules from sklearn.linear_model.**\n",
    "\n",
    "* In each case, perform systematic model selection to identify the optimal alpha parameter. \n",
    "* First, create a 20%-80% randomized split of the data. \n",
    "* Set aside the test portion; the model selection process should be performed using the 80% training data partition. \n",
    "* You should create a function that takes as input the data and target attribute; the parameter to vary and a list of its values; the model to be trained; and any other relevant input needed to determine the optimal value for the specified parameter. \n",
    "* The model selection process should perform k-fold cross validation (k should be a parameter, but you can select k=5 for this problem). \n",
    "* You should also plot the error values on the training and cross-validation splits across the specified values of the alpha parameter. Finally, using the best alpha value, run the model on the set-aside test data. \n",
    "* Discuss your observation and conclusions. [Hint: for an example of a similar model selection process please review the class example notebook.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size:  (1594, 98)\n",
      "X_test size:  (399, 98)\n",
      "y_train size:  (1594,)\n",
      "y_test size:  (399,)\n"
     ]
    }
   ],
   "source": [
    "# 80 / 20 split for data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_var, y, test_size=0.2, random_state=33)\n",
    "print(\"X_train size: \", X_train.shape)\n",
    "print(\"X_test size: \", X_test.shape)\n",
    "print(\"y_train size: \", y_train.shape)\n",
    "print(\"y_test size: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(fit_intercept=True, alpha=0.1)\n",
    "ridge.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression\n",
      "RMSE on training:  0.129880246459\n",
      "RMSE on 10-fold CV:  0.135772917737\n"
     ]
    }
   ],
   "source": [
    "p=ridge.predict(x_var)\n",
    "err=p-y\n",
    "total_error=np.dot(err,err)\n",
    "rmse_train=np.sqrt(total_error/len(p))\n",
    "\n",
    "kf=KFold(len(x_var), n_folds=10)\n",
    "xval_err=0\n",
    "for train, test in kf:\n",
    "    ridge.fit(x_var[train],y[train])\n",
    "    p=ridge.predict(x_var[test])\n",
    "    e=p-y[test]\n",
    "    xval_err+=np.dot(e,e)\n",
    "rmse_10cv=np.sqrt(xval_err/len(x_var))\n",
    "\n",
    "print(\"Ridge Regression\")\n",
    "print('RMSE on training: ', rmse_train)\n",
    "print('RMSE on 10-fold CV: ', rmse_10cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:  linear regression\n",
      "RMSE on training:  0.128691194406\n",
      "RMSE on 10-fold CV:  0.136298055672\n",
      "Method:  elastic-net\n",
      "RMSE on training:  0.232984833141\n",
      "RMSE on 10-fold CV:  0.233039434561\n",
      "Method:  lasso\n",
      "RMSE on training:  0.232984833141\n",
      "RMSE on 10-fold CV:  0.233039434561\n",
      "Method:  ridge\n",
      "RMSE on training:  0.128937729639\n",
      "RMSE on 10-fold CV:  0.135604701186\n"
     ]
    }
   ],
   "source": [
    "a=0.2\n",
    "x=x_var\n",
    "\n",
    "for name,met in[\n",
    "        ('linear regression', LinearRegression()),\n",
    "        ('elastic-net', ElasticNet(fit_intercept=True, alpha=a)),\n",
    "        ('lasso', Lasso(fit_intercept=True, alpha=a)),\n",
    "        ('ridge', Ridge(fit_intercept=True, alpha=a)),\n",
    "        ]:\n",
    "    met.fit(x_var,y)\n",
    "    p=met.predict(x_var)\n",
    "    e=p-y\n",
    "    total_error=np.dot(e,e)\n",
    "    rmse_train=np.sqrt(total_error/len(p))\n",
    "    \n",
    "    kf=KFold(len(x_var), n_folds=10)\n",
    "    err=0\n",
    "    for train, test in kf:\n",
    "        met.fit(x_var[train],y[train])\n",
    "        p=met.predict(x_var[test])\n",
    "        e=p-y[test]\n",
    "        err+=np.dot(e,e)\n",
    "    rmse_10cv = np.sqrt(err/len(x_var))\n",
    "    print('Method: ', name)\n",
    "    print('RMSE on training: ', rmse_train)\n",
    "    print('RMSE on 10-fold CV: ', rmse_10cv)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal value for the alpha parameter was 0.2 and the best methods were the elastic net and lasso regression. Ridge regression, LASSO, and elastic net are part of the same family with penalty term, alpha. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. **Next, perform regression using Stochastic Gradient Descent for regression.** \n",
    "\n",
    "* For this part, you should use the SGDRegessor module from sklearn.linear_model. Again, start with creating randomized 80%-20% train-test split. SGDRegessor requires that features be standardized (with 0 mean and scaled by standard deviation). \n",
    "* Prior to fiting the model, perform the scaling using StandardScaler from sklearn.preprocessing. For this problem, perform a grid search (using GridSearchCV from sklearn.grid_search) Your grid search should compare combinations of two penalty parameters ('l2', 'l1') and different values of alpha (alpha could vary from 0.0001 which is the default to relatively large values). \n",
    "* Using the best parameters, apply the model to the set-aside test data. \n",
    "* Finally, perform model selection (similar to part d, above) to find the best \"l1_ratio\" parameter using SGDRegressor with  the \"elasticnet\" penalty parameter. [Note: \"l1_ratio\" is The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1;  l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1 penalty; defaults to 0.15.] Using the best mixing ratio, apply the Elastic Net model to the set-aside test data. Provide a summary of your findings from the above experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent Regression\n",
      "RMSE on training:  0.146835654734\n",
      "RMSE on 10-fold CV:  0.137287003926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x_var)\n",
    "x_s=scaler.transform(x_var)\n",
    "\n",
    "sgdreg=SGDRegressor(penalty='l2', alpha=0.15, n_iter=200)\n",
    "\n",
    "# Calculate the RMSE for fitting a single model\n",
    "\n",
    "sgdreg.fit(x_var,y)\n",
    "p=sgdreg.predict(x_var)\n",
    "err=p-y\n",
    "total_error=np.dot(err,err)\n",
    "rmse_train=np.sqrt(total_error/len(p))\n",
    "\n",
    "# RMSE using 10-fold cross-validation\n",
    "\n",
    "kf=KFold(len(x_var), n_folds=10)\n",
    "xval_err = 0\n",
    "for train, test in kf:\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(x_var[train])\n",
    "    xtrain_s = scaler.transform(x_var[train])\n",
    "    xtest_s = scaler.transform(x_var[test])\n",
    "    sgdreg.fit(xtrain_s, y[train])\n",
    "    p=sgdreg.predict(xtest_s)\n",
    "    e=p-y[test]\n",
    "    xval_err += np.dot(e,e)\n",
    "rmse_10cv=np.sqrt(xval_err/len(x_var))\n",
    "\n",
    "print(\"Stochastic Gradient Descent Regression\")\n",
    "print('RMSE on training: ', rmse_train)\n",
    "print('RMSE on 10-fold CV: ', rmse_10cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. **Automatic Document Clustering [Dataset: newsgroups5.zip]**\n",
    "\n",
    "For this problem you will use a different subset of the 20 Newsgroup data set that you used in Assignment 2  (see the description of the full dataset). The subset for this assignment includes 2,500 documents (newsgroup posts), each belonging to one of 5 categories windows (0), crypt (1), christian (2), hockey (3), forsale (4). The documents are represented by 9328 terms (stems). The dictionary (vocabulary) for the data set is given in the file \"terms.txt\" and the full term-by-document matrix is given in \"matrix.txt\" (comma separated values). The actual category labels for the documents are provided in the file \"classes.txt\". Your goal in this assignment is to perform clustering on the documents and compare the clusters to the actual categories.\n",
    "\n",
    "Your tasks in this problem are the following [Note: for the clustering part of this assignment you should use the kMeans module form Ch. 10 of MLA (use the version provided here as it includes some corrections to the book version). You may also use Pandas and other modules from scikit-learn that you may need for preprocessing or evaluation.]\n",
    "\n",
    "\n",
    "a. Create your own distance function that, instead of using Euclidean distance, uses Cosine similarity. This is the distance function you will use to pass to the kMeans function.\n",
    "\n",
    "b. Load the data set [Note: the data matrix provided has terms as rows and documents as columns. Since you will be clustering documents, you'll need to take the transpose of this matrix so that your main data matrix is a document x term matrix. In Numpy, you may use the \".T\" operation to obtain the transpose.] Then, split the data set (the document x term matrix) and set aside 20% for later use (see below). Use the 80% segment for clustering in the next part. The 20% portion must be a random subset.\n",
    "\n",
    "c. As in the case of Assignment 2, transform the term-frequencies to tfxidf values. Be sure to maintain DF values for each of the terms in the dictionary. [Note: if you run into problems due to limited computational resources, you may prune the data by removing all terms with low DF values, e.g., terms that appear in less than 10 documents. Be sure to maintain the correspondence between the dictionary terms and the matrix rows.]\n",
    "\n",
    "d. Perform Kmeans clustering on the training data. Write a function to display the top N terms in each cluster along with the cluster DF values for each term and the size of the cluster. Cluster DF value for a term t in a cluster C is the percentage of docs in cluster C in which term t appears. Sort the terms in decreasing order of the DF percentage. Here is an example of how this output might look like (here the top 10 terms for 3 of the 5 clusters are displayed in decreasing order of cluster DF values, but the mean frequnecy from the cluster centroid is also shown). [Extra Credit: use your favorite third party tool, ideally with a Python based API, to create a word cloud for each cluster based on the in-cluster DF values.]\n",
    "\n",
    "e. Using the cluster assignments from Kmeans clustering, compare your 5 clusters to the 5 pre-assigned classes by computing the Completeness and Homogeneity values.\n",
    "\n",
    "f. Finally, using your cluster assignments as class labels, categorize each of the documents in the 20% set-aside data into each of the appropriate cluster. Your categorization should be based on Cosine similarity between each test document and each cluster centroids. Present your results in a separate file containing the obtained cluster label for each test document as well as Cosine similarities between each test document and each of the 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "from numpy import array\n",
    "from numpy import *\n",
    "import kNN\n",
    "import kMeans\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"newsgroups5/matrix.txt\")\n",
    "data = np.genfromtxt(\"newsgroups5/matrix.txt\",delimiter=\",\",dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9327, 2500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruned shape is:  (3367, 2500)\n",
      "prunedMat shape is:  (3367, 2500)\n",
      "(2500, 3367)\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3367,) and (1,3367) not aligned: 3367 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-301cd24c3069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweighted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mweightedMat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcentroidsPruned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclustersPruned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptsInClustersPruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkMeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweightedMat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistCosine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# --------------------- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasminedumas/Desktop/GitHub/GitHub Personal/depaul/CSC478/jupyterhw_3/kMeans.py\u001b[0m in \u001b[0;36mkMeans\u001b[0;34m(dataSet, k, distMeas, createCent)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mminDist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mminIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mdistJI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistMeas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdistJI\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mminDist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mminDist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistJI\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mminIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasminedumas/Desktop/GitHub/GitHub Personal/depaul/CSC478/jupyterhw_3/helper.py\u001b[0m in \u001b[0;36mdistCosine\u001b[0;34m(vecA, vecB)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mnorm_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mnorm_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mcosine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvecB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_A\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm_B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3367,) and (1,3367) not aligned: 3367 (dim 0) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "prunedMat = helper.pruneMat(data)\n",
    "prunedMatT = prunedMat.T\n",
    "prunedMatT.shape\n",
    "weighted = kNN.generateWeightedMatrix(prunedMatT)\n",
    "print (weighted.shape)\n",
    "print (weighted)\n",
    "weightedMat = np.mat(weighted)\n",
    "centroidsPruned, clustersPruned, ptsInClustersPruned = kMeans.kMeans(weightedMat, 5, helper.distCosine)\n",
    "\n",
    "# --------------------- #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3367)\n",
      "(500, 3367)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "tpercent = 0.8\n",
    "tsize=len(prunedMatT) * tpercent\n",
    "tsize\n",
    "pruned_train, pruned_test = train_test_split(prunedMatT, test_size=.20, random_state=42)\n",
    "print (pruned_train.shape)\n",
    "print (pruned_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3367,) and (1,3367) not aligned: 3367 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-00053b304a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcentroidsPruned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclustersPruned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptsInClustersPruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkMeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpruned_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistCosine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jasminedumas/Desktop/GitHub/GitHub Personal/depaul/CSC478/jupyterhw_3/kMeans.py\u001b[0m in \u001b[0;36mkMeans\u001b[0;34m(dataSet, k, distMeas, createCent)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mminDist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mminIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mdistJI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistMeas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdistJI\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mminDist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mminDist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistJI\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mminIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasminedumas/Desktop/GitHub/GitHub Personal/depaul/CSC478/jupyterhw_3/helper.py\u001b[0m in \u001b[0;36mdistCosine\u001b[0;34m(vecA, vecB)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mnorm_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mnorm_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mcosine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvecB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_A\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm_B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3367,) and (1,3367) not aligned: 3367 (dim 0) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "centroidsPruned, clustersPruned, ptsInClustersPruned = kMeans.kMeans(pruned_train, 5, helper.distCosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
